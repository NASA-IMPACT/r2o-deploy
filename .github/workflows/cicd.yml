# Add `runs-on: self-hosted` to your workflow's YAML to send jobs to this runner.
name: R2O CI/CD Pipeline

permissions:
  id-token: write
  contents: read
  issues: write

on:
  push:


jobs:
  build:
    runs-on: self-hosted
    name: Build
    steps:
      - name: Checkout code
        uses: actions/checkout@v2
      - name: Run test pull
        run: |
          echo "Running tests..."
          ls -lah
      - name: Install dependencies
        run: |
          echo "Installing dependencies..."
          cd /home/opkind/py-312-env
          . .venv/bin/activate
          python --version
          uv add awscli
          aws --version

  deploy:
    runs-on: self-hosted
    needs: build
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::244822573120:role/r2o-oidc
          aws-region: us-west-2

      - name: Get secret from AWS Secrets Manager and create .env file
        env:
          SECRET_NAME: r20-deployment-dev
          $AWS_REGION: us-west-2
        run: |
          cd /home/opkind/py-312-env
          . .venv/bin/activate
          SECRET_STRING=$(aws secretsmanager get-secret-value \
            --secret-id "$SECRET_NAME" \
            --region "$AWS_REGION" \
            --query SecretString \
            --output text)
          echo "$SECRET_STRING" | jq -r 'to_entries|map("\(.key)=\(.value)")|.[]' > .env

      - name: List S3 buckets
        run: |
          echo "Listing S3 buckets:"
          cd /home/opkind/py-312-env
          . .venv/bin/activate
          cat .env
          aws s3 ls
          echo "Detailed S3 bucket information:"
          aws s3api list-buckets --query "Buckets[].Name" --output table

      - name: Deploy to neo server
        run: |
          echo "Deploying to production server..."
          kubectl get pods -n argocd
          kind get clusters

